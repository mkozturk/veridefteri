{
  "hash": "dc9214d452a9af1c4fed8ac94272d909",
  "result": {
    "markdown": "---\ntitle: Aşırı Öğrenme ve Eksik Öğrenme\nauthor: Birol Yüceoğlu\ndate: '2017-11-07'\ncategories:\n  - yapay öğrenme\n---\n\n![](wall-e-1872683_640.webp)\n\nMakine öğrenmesi uygulamalarında temel amaç eldeki veriden örüntüler öğrenmek, bu örüntüleri kullanarak değer oluşturmaktır. Örnek olarak müşterilerin özelliklerine bakarak terk edecek ya da kampanyanızdan yararlanacak müşterileri tahmin etmeye çalışabilirsiniz. Bir tavsiye sistemi kurarak müşterilerinize ilgilenecekleri ürünleri önermeye çalışabilirsiniz. Ya da bir bölgedeki evlerin özelliklerine ve fiyatlarına bakarak ilgilendiğiniz evin fiyatının düşük ya da yüksek olup olmadığını yorumlamak isteyebilirsiniz. Bulacağınız örüntüler gerçek hakkında size ipucu verecek modellere denk geliyor. Gerçeği tam olarak tahmin etmeniz imkansız olsa da model kurarken kaçınmanız gereken iki hata tipi var. Bu Veri Defteri'nde *Aşırı Öğrenme* (overfitting) ve *Eksik Öğrenme* (underfitting) kavramlarından bahsedeceğiz.\n\n* *Eksik Öğrenme*: Modelin gözlemlerdeki örüntüyü eksik yakalaması durumuna denir. Örnek olarak karekök fonksiyonunu ya da ikinci dereceden bir denklemi bir doğru ile yakınsamayı gösterebiliriz.\n* *Aşırı Öğrenme*: Modelin örüntüler yerine gözlemleri öğrenmeye başlamasıdır. Bu durumda öğrenme için kullandığınız veri setini öğrenirsiniz. Ancak bu şekilde oluşturacağınız modeller yeni ve daha önceden görmediğiniz gözlemlerle karşılaştığında başarılı bir tahmin yapma olasılığınızı azaltır. \n\nBu kavramlara bir kaç örnekle bakmayı deneyelim. İlk olarak kullanacağımız paketleri yükleyelim.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n%matplotlib inline\n# Aşağıdaki iki satır uyarı mesajlarını kapatmaya yarıyor\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nfrom IPython.display import display, HTML\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#Veri setini bölmek için\nfrom sklearn.model_selection import train_test_split\n\n#Kullanacağımız doğrusal bağlanım (linear regression) ve gradient boosting yöntemleri\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#Yapay sınıflandırma verisi oluşturmak için gerekli bir fonksiyon\nfrom sklearn.datasets import make_classification\n\n#Sonuçları değerlendirmek için gerekli fonksiyonlar\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\n#Veriyi istediğimiz dereceden değişkenlerden oluşturmak için PolynomialFeatures kullanacağız.\nfrom sklearn.preprocessing import PolynomialFeatures\n```\n:::\n\n\nKavramları göstermek için yapay bir veri seti oluşturalım. Çıktı ile girdi arasında doğrusal bir ilişki kurduğum için doğrusal bağlanım yöntemiyle bu veri setindeki örüntüyü öğrenmeye çalışacağız. İlk olarak 75 gözlemden oluşan bir yapay veri seti oluşturalım. `train_test_split()` fonksiyonu veriyi öğrenme (training) ve sınama (testing) için iki kümeye ayıracak.\n\nKuracağımız ilişki $y = 2.5 x + \\epsilon$ şeklinde olacak. Burada en sondaki terim rassal olarak eklediğimiz bir gürültüye (noise) denk geliyor.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nnum_obs = 75\n#Random seed her bilgisayarda aynı sonucu elde etmek için kullanılan bir fonksiyon. \n#Ancak versiyon değişiklikleri gibi nedenlerle farklı sonuçlar elde edebilirsiniz.\n\nnp.random.seed(1)\nX = np.random.rand(num_obs)*10\ny = 2.5 * X + np.random.randn(num_obs)*2\n\n#Veriyi %80 öğrenme ve %20 sınama şeklinde ikiye ayırıyoruz.\nX_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, random_state = 0)\n```\n:::\n\n\nÖrüntüyü görmek için bir serpme (`scatter`) grafiği kullanalım. \n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nplt.figure(figsize=(8,8))\nplt.scatter(X_train,y_train)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-4-output-1.png){width=641 height=633}\n:::\n:::\n\n\nGördüğümüz gibi veri setinde girdi ve çıktı arasında doğrusal bir ilişki var. *x* değeri bir birim arttığında *y* değişkeninin değeri yaklaşık olarak 2.5 birim artıyor. Bir doğrusal bağlanım (linear regression) modeliyle bu ilişkiyle ilgili bilgileri elde edebiliriz. Bu amaçla `LinearRegression()` fonksiyonunu kullanacağız.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n#Modeli oluşturalım.\nlr = LinearRegression()\n#X_train ve y_train değerleriyle modeli eğitelim. \n#.reshape(-1,1) kısmı tek boyutlu değişkenlerle çalıştığımız için gerekli olan bir fonksiyon.\nlr.fit(X_train.reshape(-1,1),y_train.reshape(-1,1))\nprint(\"Kesişim (Intercept): \" + str(lr.intercept_))\nprint(\"Eğim (Slope): \" + str(lr.coef_[0]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nKesişim (Intercept): [0.82241911]\nEğim (Slope): [2.43747185]\n```\n:::\n:::\n\n\nModele göre *x* değişkeninin değeri bir birim arttığı zaman *y* değişkeninin değeri 2.44 birim artıyor. Bu da bizim oluşturduğumuz örüntüye (2.5*x*) oldukça yakın bir değer. *x* değeri sıfıra eşit olduğunda ise *y* değeri 0.82 oluyor. Bu bilgiyi test edeceğimiz veri setinde kullanarak sonuçları değerlendirebiliriz. \n\nAşağıdaki şekilde mavi noktalar öğrenme verisini, kırmızı noktalar sınama verisini ve yeşil çizgi de elde ettiğimiz modelin çıktısını temsil ediyor.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n#0 ile 10 arasındaki değerler için modelin sonuçlarını elde edelim.\nline_X = np.arange(0,11, 0.1)\nline_y = lr.predict(line_X.reshape(-1,1))\n\nplt.figure(figsize=(8,8))\nplt.scatter(X_train,y_train, alpha = 0.5, label = 'Öğrenme')\nplt.scatter(X_test, y_test, c='red', alpha = 0.7, label = 'Sınama')\nplt.plot(line_X, line_y, c='green', linewidth=3, alpha=0.6, label = 'Doğrusal Bağlanım')\nplt.legend(loc = 4)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-6-output-1.png){width=641 height=633}\n:::\n:::\n\n\nGördüğümüz gibi doğrusal bağlanım sınama verisini başarıyla tahmin edebiliyor. \n\nAşırı Öğrenme ve Eksik Öğrenme kavramlarını anlatmak için veride doğrusal olmayan bir ilişki oluşturalım. Kullanacağımız yeni modelde ilişkiyi bu şekilde değiştiriyoruz: $y' = y + 80 y^2 - 4 y^3$. Ben doğrusal olmayan örüntüyü daha belirgin hale getirmek için yeni çıktıları hesaplarken eski çıktı değerlerini kullanmayı tercih ettim.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ny_train = y_train +  80* np.power(y_train, 2) - 4 * np.power(y_train, 3)\ny_test = X_test +  80* np.power(y_test, 2) - 4 * np.power(y_test, 3) \n```\n:::\n\n\nTekrar bir doğrusal bağlanımla modelin öğrenme yeteneğini inceleyelim. Öğrenme yeteneğini daha objektif bir şekilde incelemek için de karesel ortalama hatanın kareköküne (root mean square error, RMSE) bakacağız. Karesel ortalama hata hesaplanırken gözlemin gerçek değeriyle model sonucu elde edilen tahmin arasındaki farkların karelerinin ortalaması alınır ve bu değerin karekökü hesaplanır. Bu şekilde tahmin ettiğimiz değerlerle gerçek gözlemlerin birbirinden ne kadar uzak olduğu bilgisi elde edilir. Kabaca bu değerin düşük olması modelin tahmin yeteneğinin güçlü olduğunu işaret eder diyebiliriz.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#Modeli oluşturuyoruz.\nlr = LinearRegression()\n#X ve y değerleriyle modelin öğrenmesini sağlıyoruz.\nlr.fit(X_train.reshape(-1,1),y_train)\n#Modelin sonucunu görmek için 0 ve 10 aralığında tahmin yapıyoruz.\nline_y = lr.predict(line_X.reshape(-1,1))\n\n\nprint(\"Öğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_train, lr.predict(X_train.reshape(-1,1))))))\nprint(\"Sınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_test, lr.predict(X_test.reshape(-1,1))))))\n\nplt.figure(figsize=(8,8))\nplt.scatter(X_train,y_train, alpha = 0.3)\nplt.scatter(X_test, y_test, c='red', alpha = 0.7)\nplt.plot(line_X, line_y, c='green', linewidth=3)\nplt.ylim((-30000, 10000))\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nÖğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 5204.605138576858\nSınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 4694.645928019619\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-8-output-2.png){width=677 height=638}\n:::\n:::\n\n\nDoğrusal bağlanım tek bir değişkenle üçüncü dereceden bir denklemi öğrenemedi. İkinci ve üçüncü dereceden değişkenler eklersek modelin öğrenme yeteneği artacaktır. Bu değişkenleri eklemek için `PolynomialFeatures()` fonksiyonunu kullanıyoruz. Öncelikle ikinci dereceden değişkenler oluşturalım.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Degree değerini iki yaparak x ve x^2 değişkenlerini modele ekliyoruz.\npf = PolynomialFeatures(degree=2, include_bias=False)\n\n#Polynomial features fit/transform fonksiyonlarını kullanıyor.\nX_train_new = pf.fit_transform(X_train.reshape(-1,1))\nX_test_new = pf.transform(X_test.reshape(-1,1))\n#0 ve 10 değerleri arasında bağlanım değerlerini çizdirmek için kullanacağız.\nline_X_new = pf.transform(line_X.reshape(-1,1))\n\n#Modeli oluşturup öğrenmesini sağlıyoruz.\nlr = LinearRegression()\nlr.fit(X_train_new,y_train)\nprint(\"Öğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_train, lr.predict(X_train_new)))))\nprint(\"Sınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_test, lr.predict(X_test_new)))))\n\n#0 ve 10 değerleri arasında bağlanım değerlerini çizdirmek için kullanacağız.\nline_y = lr.predict(line_X_new)\n\n\nplt.figure(figsize=(8,8))\nplt.scatter(X_train,y_train, alpha = 0.3)\nplt.scatter(X_test, y_test, c='red', alpha = 0.7)\nplt.plot(line_X, line_y, c='green', linewidth=3)\nplt.ylim((-30000, 10000))\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nÖğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 3414.8825409044716\nSınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 2199.330416057473\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-9-output-2.png){width=677 height=638}\n:::\n:::\n\n\nİkinci dereceden değişkenler sayesinde hem öğrenme hem de sınama veri setinde hatayı azaltmayı başardık. Ancak örüntüyü tam olarak yakalayamadığımız da açık. Şimdi bir de üçüncü dereceden değişkenleri deneyelim.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Degree değerini üç yaparak x, x^2 ve x^3 değişkenlerini modele ekliyoruz.\npf = PolynomialFeatures(degree=3, include_bias=False)\n\n#Polynomial features fit/transform fonksiyonlarını kullanıyor.\nX_train_new = pf.fit_transform(X_train.reshape(-1,1))\nX_test_new = pf.transform(X_test.reshape(-1,1))\n#0 ve 10 değerleri arasında bağlanım değerlerini çizdirmek için kullanacağız.\nline_X_new = pf.transform(line_X.reshape(-1,1))\n\n#Modeli oluşturup öğrenmesini sağlıyoruz.\nlr = LinearRegression()\nlr.fit(X_train_new,y_train)\nprint(\"Öğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_train, lr.predict(X_train_new)))))\nprint(\"Sınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_test, lr.predict(X_test_new)))))\n\n#0 ve 10 değerleri arasında bağlanım değerlerini çizdirmek için kullanacağız.\nline_y = lr.predict(line_X_new)\n\n\nplt.figure(figsize=(8,8))\nplt.scatter(X_train,y_train, alpha = 0.3)\nplt.scatter(X_test, y_test, c='red', alpha = 0.7)\nplt.plot(line_X, line_y, c='green', linewidth=3)\nplt.ylim((-30000, 10000))\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nÖğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 2751.4685999151775\nSınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 1238.2399802882837\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-10-output-2.png){width=677 height=638}\n:::\n:::\n\n\nHatayı azaltmayı başardık. Değişken sayısını arttırırsak daha iyi sonuçlar elde edeceğiz gibi duruyor. Belki de on beşinci dereceden değişkenleri modele ekleyerek daha iyi bir sonuç elde edebiliriz.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# Degree değerini on beş yapıyoruz.\npf = PolynomialFeatures(degree=15, include_bias=False)\n\n#Polynomial features fit/transform fonksiyonlarını kullanıyor.\nX_train_new = pf.fit_transform(X_train.reshape(-1,1))\nX_test_new = pf.transform(X_test.reshape(-1,1))\n#0 ve 10 değerleri arasında bağlanım değerlerini çizdirmek için kullanacağız.\nline_X_new = pf.transform(line_X.reshape(-1,1))\n\n#Modeli oluşturup öğrenmesini sağlıyoruz.\nlr = LinearRegression()\nlr.fit(X_train_new,y_train)\nprint(\"Öğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_train, lr.predict(X_train_new)))))\nprint(\"Sınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): \" \n      + str(np.sqrt(mean_squared_error(y_test, lr.predict(X_test_new)))))\n\n#0 ve 10 değerleri arasında bağlanım değerlerini çizdirmek için kullanacağız.\nline_y = lr.predict(line_X_new)\n\n\nplt.figure(figsize=(8,8))\nplt.scatter(X_train,y_train, alpha = 0.3)\nplt.scatter(X_test, y_test, c='red', alpha = 0.7)\nplt.plot(line_X, line_y, c='green', linewidth=3)\nplt.ylim((-30000, 10000))\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nÖğrenme verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 2194.1279169602035\nSınama verisinde karesel ortalama hata (Root Mean Square Error, RMSE): 13654.583865130366\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-11-output-2.png){width=677 height=638}\n:::\n:::\n\n\nŞekilde gördüğümüz gibi model veriyi çok başarılı bir şekilde öğrenmeyi başardı. Öğrenme verisindeki hata da düşmüş durumda. Ama aynı şeyi sınama verisi için söyleyemeyiz. Sınama verisinde hatanın tam tersine arttığını görüyoruz. Şimdi `PolynomialFeatures` altındaki `degree` (derece) değişkeninin birden 15'e çıkararak her bir değer için hataların durumuna bakalım. \n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n#Karesel Ortalama Hata değerleri, öğrenme ve sınama veri setleri için\nscore_train = np.zeros(16)\nscore_test = np.zeros(16)\n\n#1 ile 15 arasında dereceyi değiştirerek sonuçları tutuyoruz.\nfor i in range(1,16):\n    pf = PolynomialFeatures(degree=i, include_bias=False)\n    X_train_new = pf.fit_transform(X_train.reshape(-1,1))\n    X_test_new = pf.transform(X_test.reshape(-1,1))\n    lr = LinearRegression()\n    lr.fit(X_train_new,y_train)\n    score_train[i] = np.sqrt(mean_squared_error(y_train, lr.predict(X_train_new)))\n    score_test[i] = np.sqrt(mean_squared_error(y_test, lr.predict(X_test_new)))\n\n#Sonuçları daha güzel çizmek için ilk değeri boş bırakıyoruz\nscore_test[0] = np.nan\nscore_train[0] = np.nan\n\nplt.figure(figsize=(10,5))\nplt.plot(score_train, color = 'blue', label = 'Öğrenme')\nplt.plot(score_test, color = 'red', label = 'Sınama')\nplt.xlabel('Derece')\nplt.ylabel('RMSE')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-12-output-1.png){width=833 height=429}\n:::\n:::\n\n\nGördüğümüz gibi `PolynomialFeatures` altındaki derece sayısını arttırdıkça öğrenme veri setini daha iyi öğreniyoruz. Ancak öğrendiğimiz örüntüler sınama verisinde işimize yaramıyor. Üçüncü dereceden itibaren hata artıyor. Dokuzuncu derecedeki düşüş de muhtemelen bir örüntüden çok şansla ilgili.\n\nAşırı Öğrenme ve Eksik Öğrenme sınıflandırma problemlerinde de karşımıza çıkabilecek bir durum. Bunu da yine yapay bir veri seti üzerinde inceleyelim. Bu amaçla `scikit-learn` altındaki `make_classification()` fonksiyonunu kullanacağız.\n\nÖğrenme algoritması olarak `GradientBoostingClassifier()` yöntemini seçtik. Bu yöntem iterasyonlarla ilerleyen bir yöntem. Her iterasyonda bir önceki iterasyonun hatalarını düzeltmeyi amaçlıyor. İterasyon sayısının öğrenme yeteneğindeki etkisine bakalım. Değerlendirme için isabetlilik (accuracy) değerine bakacağız. Bu da modelin yaptığı doğru tahminin yüzdesine denk geliyor.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# 3000 örnek ve 100 öznitelikten oluşan bir veri seti oluşturuyoruz. \n# flip_y değeri sayesinde etiketlerin %25'inin değerini değiştiriyoruz. Bu sayede daha zor bir problem elde edeceğiz.\nX,y = make_classification(n_samples = 3000, n_features=100, flip_y = 0.25, random_state= 100 )\n\n#Veriyi öğrenme ve sınama veri setlerine ayırıyoruz.\nX_train, X_test, y_train, y_test = train_test_split(X,y,train_size = 0.80, random_state = 100)\n\n#Öğrenme için iteratif bir yöntem olan GradientBoosting'i kullanacağız.\n#İterasyon sayısını az tuttuğumuzda yeterince öğrenememe, fazla tuttuğumuzda ise ezberleme durumu ortaya çıkabilir.\n#200 iterasyon kullanarak modeli ouşturup öğrenmesini sağlayalım.\n#Modelin performansını değerlendirmek için doğru tahmin yüzdesini (accuracy) kullanacağız.\nclf = GradientBoostingClassifier(n_estimators = 200, random_state= 0 )\nclf.fit(X_train, y_train)\n\nprint('Öğrenme versinde isabetlilik: ' + str(accuracy_score(clf.predict(X_train),y_train)))\nprint('Sınama verisinde isabetlilik: ' + str(accuracy_score(clf.predict(X_test),y_test)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nÖğrenme versinde isabetlilik: 0.935\nSınama verisinde isabetlilik: 0.8066666666666666\n```\n:::\n:::\n\n\nGördüğümüz gibi öğrenme verisinde isabetlilik gayet yüksekken, sınama verisinde bu değer daha düşük. Bu normal bir durum olsa da aradaki fark aşırı öğrenmeye işaret ediyor olabilir. Şimdi bir de her iterasyonda ne olduğunu inceleyelim.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# İsabetlilik değerlerini içeren diziler\nscore_test = np.zeros((200,), dtype=np.float64)\nscore_train = np.zeros((200,), dtype=np.float64)\n\n#İsabetlilik değerlerini dolduruyoruz. Staged_predict fonksiyonu her iterasyonun sonuçlarını döndürmek için kullanılıyor.\nfor i, y_pred in enumerate(clf.staged_predict(X_test)):\n    score_test[i] = accuracy_score(y_test, y_pred)\n\nfor i, y_pred in enumerate(clf.staged_predict(X_train)):\n    score_train[i] = accuracy_score(y_train, y_pred)\n\n\nprint('Enbüyük isabetlilik değeri: ' + str(score_test.max()) )\nprint('Enbüyük isabetlilik değerinin elde edildiği iterasyon: ' + str(score_test.argmax()) )\n\nplt.figure(figsize = (10,5))\nplt.plot(score_train, label='Öğrenme', c= 'blue')\nplt.plot(score_test, label='Sınama', c = 'red')\nplt.ylim((0.8,0.95))\nplt.xlabel('İterasyon')\nplt.ylabel('İsabetlilik')\nplt.legend(loc=5)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEnbüyük isabetlilik değeri: 0.8166666666666667\nEnbüyük isabetlilik değerinin elde edildiği iterasyon: 46\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Asiri_Eksik_Ogrenme_files/figure-html/cell-14-output-2.png){width=821 height=432}\n:::\n:::\n\n\nGördüğümüz gibi öğrenme verisinde hatamız gitgide düşüyor. Muhtemelen iterasyon sayısını arttırırsak öğrenme verisini tamamen doğru bir şekilde öğrenebileceğiz. Gerçi buna öğrenmek yerine ezberlemek demek daha doğru. Sınama verisinde en iyi isabetliliği 46. iterasyonda elde ediyoruz. Bu iterasyondan önce ve sonra isabetlilik değerleri daha düşük. Öncesinde veriyi öğrendiğimizi (underfitting) sonrasında ise ezberlediğimizi (overfitting) söyleyebiliriz. Bu örnekte fark küçük de olsa gerçek uygulamalarda bu dengeyi başarılı bir şekilde tutturmak projenizin başarısını belirleyen faktör olabilir.\n\nBu Veri Defteri'ni [github](https://github.com/sibirbil/VeriDefteri) dizininde bulabilirsiniz. \n\n",
    "supporting": [
      "Asiri_Eksik_Ogrenme_files"
    ],
    "filters": [],
    "includes": {}
  }
}